{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seção 2 - Deep Learning and Tensorflow Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deep Learning**: é uma sub-área de Machine Learning que envolve o aprendizado profundo de máquina, em que algoritmos buscam padrões em fontes de dados desestruturados, como textos, imagens, áudios. A modelagem acontece pelas redes neurais, que são estruturas que recebem, processam e constroem os modelos a partir dos dados, além de corrigir os erros e otimizar os parâmetros para aumentar a acurácia desses modelos. Assim, o Deep Learning atua como uma arquitetura de processamento e modelagem de dados não-estruturados, de forma automatizada a partir dos dados de input, resultando em previsões do objeto real em questão.\n",
    "\n",
    "- **Redes Neurais**: As redes neurais são estruturas de processamento de dados que formam a arquitetura do Deep Learning. Como disse logo acima, elas buscam imitar o processo da cognição humana ao conectar diversas camadas de neurônios artificiais.Esses neurônios atuam combinando os dados recebidos, atribuindo-lhes pesos e vieses e associando-os a funções específicas de custo e ativação. Dessa forma, esses elementos trabalham juntos para definir as etapas de processamento até o output, que deve reconhecer, classificar ou descrever objetos reais a partir dos dados.\n",
    "\n",
    "No Machine Learning, temos dados que são, na maioria das vezes, estruturados, e o procedimento de treinamento de um modelo com regras que encontramos ao manipular e processar os dados, além de haver um valor-alvo para basearmos a resposta do modelo em cada exemplo. No Deep Learning, temos apenas um input e um output esperado, e deixamos que as redes neurais processem os dados, encontrem alguma forma de estruturá-los e busquem por padrões que possam ajudar a chegar no resultado do output que esperamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um problema complexo, como ensinar um carro a dirigir sozinho, que possui um volume muito grande de dados, o Deep Learning pode ser a alternativa mais viável. Uma vez que estamos lidando com dados desestruturados e em grande volume, a estrutura de redes neurais traz uma capacidade de lidar de maneira mais eficiente com uma variedade de parâmetros e filtrá-los de acordo com sua relevância em cada camada.\n",
    "\n",
    "**O Deep Learning é indicado para as seguintes situações:**\n",
    "\n",
    "- Problemas com longas listas de regras\n",
    "- Ambientes que mudam constantemente, i.e, Adaptação a novos cenários\n",
    "- Descobrir insights em grandes quantidades de dados\n",
    "\n",
    "**Deep Learning não é indicado nas seguintes situações:**\n",
    "\n",
    "- Quando necessitamos interpretabilidade: os padrões de DL normalme}nte não são interpretáveis por humanos\n",
    "- Quando a abordagem tradicional é melhor, isto é, com um sistema de regras simples\n",
    "- Quando erros são inaceitáveis, pois outputs no DL podem ser imprevisíveis \n",
    "- Quando não há muitos dados disponíveis, pois modelos de DL necessitam de grandes quantidade de dados para manter uma boa performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow é uma biblioteca de Machine Learning end-to-end. Nela, é possível escrever códigos de DL em Python e rodá-los utilizando GPU (Graphics Processing Units) ou TPU (Tensor Processing Units). O Tensorflow permite o pré-processamento dos dados, modelagem e deploy de aplicações, além de oferecer um hub de modelos já construídos de DL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do Tensorflow: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Versão do Tensorflow: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.constant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar tensores com tf.constant()\n",
    "scalar = tf.constant(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um tensor constante de ordem zero, ou seja, um escalar. O escalar é simplesmente a representação de um número. Se checarmos o número de dimensões desse tensor escalar, resultará em:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {scalar.ndim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 2])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = tf.constant([7, 2])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que, para criar um vetor, passamos uma lista de números para a função `tf.constant()`. Vamos checar as dimensões do vetor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {vector.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de se esperar, o vetor já é um tensor de grau 1, contendo portanto uma dimensão. Se aumentarmos a dimensão, teremos uma matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 2],\n",
       "       [3, 6]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tf.constant([[5, 2],\n",
    "                     [3, 6]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {matrix.ndim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float16, numpy=\n",
       "array([[ 3.,  5.,  1.],\n",
       "       [ 5., 12., 43.],\n",
       "       [ 2.,  5.,  8.]], dtype=float16)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Especificando o tipo dos dados no tensor\n",
    "matrix_2 = tf.constant([[3., 5., 1.],\n",
    "                        [5., 12., 43.],\n",
    "                        [2., 5., 8.]], dtype = tf.float16)\n",
    "matrix_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipular os tipos dos dados é útil, pois pode economizar espaço de armazenamento das variáveis nas unidades de processamento, tornando os processos mais rápidos. Para número que não carregam tanta precisão, podemos utilizar um tipo de dados que ocupa menos espaço.\n",
    "\n",
    "Note que essa matriz possui um formato diferente da primeira, contudo o número de dimensões continua o mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {matrix_2.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, para criar um tensor, precisamos aumentar a dimensão mais uma vez para ter um tensor de grau 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[1, 2, 4],\n",
       "        [2, 5, 7]],\n",
       "\n",
       "       [[4, 1, 6],\n",
       "        [6, 8, 8]],\n",
       "\n",
       "       [[4, 6, 1],\n",
       "        [6, 2, 1]]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant([[[1, 2, 4],\n",
    "                       [2, 5, 7]], \n",
    "                       [[4, 1, 6],\n",
    "                       [6, 8, 8]],\n",
    "                       [[4, 6, 1],\n",
    "                        [6, 2, 1]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preste atenção ao _shape_, temos 3 matrizes, de 2 linhas e 3 colunas cada. Vamos checar as dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {tensor.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criado portanto um tensor de grau 3. Assim, criamos diferentes tipos de tensores que variam em seu grau, ou dimensões:\n",
    "\n",
    "- Escalar: tensor de grau zero;\n",
    "- Vetor: tensor de grau 1 (e.g, Força);\n",
    "- Matrix: tensor de grau 2 (e.g, Matriz de condutividade);\n",
    "- Tensor: um arranjo numérico n-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.Variable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentemente do `tf.constant()`, o `tf.Variable()` criar tensores cujos elementos podem mudar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 1])>,\n",
       " <tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([5, 1])>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando tensores constantes e variáveis\n",
    "unchangeable_tensor = tf.constant([5, 1])\n",
    "changeable_tensor = tf.Variable([5, 1])\n",
    "\n",
    "unchangeable_tensor, changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([6, 1])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alterando elementos do tensor variável\n",
    "changeable_tensor[0].assign(6)\n",
    "\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que foi alterado o primeiro elemento do tensor variável. Se tentarmos fazer o mesmo com o tensor constante, obviamente teríamos um erro, pois os elementos não podem mudar.\n",
    "\n",
    "Raramente será preciso decidir entre usar o tensor constante ou o variável. Durante as aplicações, o próprio TensorFlow toma essa decisão por nós."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensores randômicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensores randômicos são tensores de tamanho arbitrário que contém números gerados aleatoriamente. As redes neurais utilizam tensores randômics para inicializar os pesos dos parâmetros ao receber dados de input, sendo o primeiro passo para compreender os dados. Por exemplo, o processo de aprendizado da rede neural envolve tomar um arranjo n-dimensional de número e refiná-lo até que ele represente algum padrão (uma forma comprimida de representar os dados originais)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando dois tensores aleatórios (porém iguais)\n",
    "random_1 = tf.random.Generator.from_seed(42)\n",
    "random_1 = random_1.normal(shape = (3, 2))\n",
    "\n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape = (3, 2))\n",
    "\n",
    "random_1, random_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       "array([[ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_1 == random_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que apesar de os números parecerem randômicos, eles não são realmente. Por termos definido uma _seed_ para o gerador de números aleatórios, e depois termos pedido para gerar os números aleatórios de acordo com uma distribuição qualquer (neste caso, a normal), a _seed_ garante a reproducibilidade dos dados. É como se pedíssemos números aleatórios, mas com um tempero específico, que é a _seed_. Assim, ambos os tensores contém a mesma _seed_ de geração, de modo que ao aplicar a mesma distribuição, eles serão iguais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embaralhando a ordem dos elementos no tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual a necessidade de embaralhar elementos em um tensor?\n",
    "\n",
    "A ordem dos dados pode afetar a maneira como a rede neural aprende, de modo que ela começa a organizar seus pesos de acordo com o padrão que encontrou devido simplesmente ao ordenamento dos dados, não porque identificou características nos atributos que realmente diferenciam os objetos na realidade.\n",
    "\n",
    "Vamos supor que temos um conjunto de dados que contém 10000 imagens de gatos seguidas por 5000 imagens de cachorros. Por causa das primeiras 10 mil imagens serem apenas de gatos, o algoritmo pode perceber a ordem e classificar de acordo com isso, ao invés de padrões subjacentes nos dados. Isso pode levar ao overfitting do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[4, 3],\n",
       "       [1, 4],\n",
       "       [5, 7]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_shuffled = tf.constant([[4, 3],\n",
    "                            [1, 4],\n",
    "                            [5, 7]])\n",
    "not_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[4, 3],\n",
       "       [5, 7],\n",
       "       [1, 4]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Emabaralhando o tensor\n",
    "shuffled = tf.random.shuffle(not_shuffled)\n",
    "shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[4, 3],\n",
       "       [5, 7],\n",
       "       [1, 4]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embaralhando com uma seed para geração\n",
    "tf.random.set_seed(10) # seed global\n",
    "seed_shuffle = tf.random.shuffle(not_shuffled, seed = 10) # seed operacional\n",
    "seed_shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que no primeiro caso, em que apenas embaralhamos os elementos dos tensor, a cada atualização na célula temos uma nova ordem de elementos no tensor. No segundo caso, em que definimos uma _seed_ global e uma operacional, e as duas são iguais, os elementos são embaralhados, mas a _seed_ garante a reproducibilidade a cada atualização da célula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando tensores de arrays NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos que é possível construir tensores constantes, que não permitem mudanças nos seus elementos, e tensores variáveis, que permitem a mudança dos seus elementos mediante uso do método `assign()`. Além disso, vimos a importância dos tensores randomizados para o uso em redes neurais e no aprendizado de máquina. A randomização é o primeiro processo que ocorre após o algoritmo receber os inputs, pois ele inicializa os pesos de forma aleatória para serem ajustados posteriormente. \n",
    "\n",
    "Outro ponto importante abordado foi o uso do embaralhamento (shuffle) dos tensores que contém os dados. Dependendo do conjunto de dados, podemos ter muitos exemplos consecutivos com o mesmo rótulo, de modo que o algoritmo percebe essa ordem nos dados e passa a classificar de acordo com ela, perdendo a capacidade de generalização e levando até ao overfitting. Para isso, o método `tf.random.shuffle()` embaralha os elementos de um tensor, forçando o algoritmo a buscar padrões mais representativos do objeto real.\n",
    "\n",
    "Como cada atualização do código pode levar a um resultado diferente do embaralhamento, é comum utilizar as sementes (seed) para garantir a reproducibilidade da alearoriedade dos experimentos. Isto é, garantimos que o embaralhamento acontecerá de uma forma a cada atualização. Para isso, utiliza-se um seed global com `tf.random.set_seed(x)` juntamente com uma seed operacional no tensor, passada como parâmetro para `tf.random.shuffle(seed = x)`\n",
    "\n",
    "Agora, iremos estudar maneiras de construir tensores a partir de arranjos Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor que contém todos os elementos iguais a um\n",
    "tf.ones([4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor com todos os elementos iguais a zero\n",
    "tf.zeros([4, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferença entre os conjuntos numéricos feitos por NumPy e tensores do Tensorflow é que estes podem rodar na GPU, que é muito mais rápida para processamento. Vamos criar um array NumPy e construir um tensor a partir dele. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_A = np.arange(1, 25, dtype = 'int32')\n",
    "array_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24], shape=(24,), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant(array_A)\n",
    "print(A)\n",
    "print(type(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18],\n",
       "        [19, 20, 21],\n",
       "        [22, 23, 24]]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos manipular o formato (shape) do tensor a partir da construção com array Numpy\n",
    "B = tf.constant(array_A, shape = (2, 4, 3))\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos manipular as dimensões dos tensores criados a partir dos arranjos Numpy. Porém, devemos nos atentar que o shape deve ser tal que a multiplicação das componentes da dimensão é igual ao número de elementos no arranjo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informações sobre os tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_rank_4 = tf.zeros(shape = [3, 2, 3, 2])\n",
    "tf_rank_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informações sobre o tensor: \n",
      "Shape: (3, 2, 3, 2) \n",
      "Número de dimensões: 4 \n",
      "Tamanho: 36 \n",
      "Tipos: <dtype: 'float32'> \n",
      "Elementos no eixo zero: 3 \n",
      "Elementos no último eixo: 2\n"
     ]
    }
   ],
   "source": [
    "print('Informações sobre o tensor:',\n",
    "      f'\\nShape: {tf_rank_4.shape}',\n",
    "      f'\\nNúmero de dimensões: {tf_rank_4.ndim}',\n",
    "      f'\\nTamanho: {tf.size(tf_rank_4)}', # size = 3 x 2 x 3 x 2\n",
    "      f'\\nTipos: {tf_rank_4.dtype}',\n",
    "      f'\\nElementos no eixo zero: {tf_rank_4.shape[0]}',\n",
    "      f'\\nElementos no último eixo: {tf_rank_4.shape[-1]}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexando e expandindo tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeiros dois elementos de cada dimensão\n",
    "tf_rank_4[:2, :2, :2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeiro elemento de cada dimensão exceto a última\n",
    "tf_rank_4[:1, :, :, :] # Primeiro conjunto de matrizes\n",
    "tf_rank_4[:1, :1, :, :] # Dentro do primeiro conjunto de matrizes, pego a primeira matriz\n",
    "tf_rank_4[:1, :1, :1, :] # Dentro da primeira matriz, pego a primeira linha\n",
    "tf_rank_4[:1, :1, :1, :1] # Dentro da primeira linha, pego o primeiro elemento da primeira coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_rank_2 = tf.constant([[10, 7],\n",
    "                         [3, 4]])\n",
    "tf_rank_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos buscar o último elemento de alguma dimensão dos tensores utilizando a indexação [-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 4])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_rank_2[:, -1] # Todos os elementos da última coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_rank_2[-1, :] # Todos os elementos da última linha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos manipular as dimensões de um tensor expandindo-o ao longo de alguma dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_rank_3 = tf_rank_2[..., tf.newaxis]\n",
    "tf_rank_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expandindo o tensor, adicionando uma nova dimensão\n",
    "tf.expand_dims(tf_rank_2, axis = -1) # Mesma operação, com método diferente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operações básicas com tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se os dados estão armazenados no formato de tensor, encontrar padrões nos tensores envolve aplicar operações para manipulá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionar valores ao tensor com o operador de adição\n",
    "tensor_1 = tf.constant([[10, 7],\n",
    "                        [3, 4]])\n",
    "\n",
    "tensor_1 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando adicionamos valores da forma como fizemos acima, o tensor não é modificado em si. Para que o resultado da operação seja o novo tensor, é preciso associar à variável, e.g, _tensor_1 = tensor_1 + 10_.\n",
    "\n",
    "Podemos utilizar as funções do Tensorflow para operações básicas. Os tensores manipulados com as funções próprias do Tensorflow são processadas mais rapidamente, o que pode economizar tempo durante projetos com muitas operações nos tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionando os valores e modificando o tensor\n",
    "tf.add(tensor_1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[30, 21],\n",
       "       [ 9, 12]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicando o mesmo tensor\n",
    "tf.multiply(tensor_1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplicação de matrizes com tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma das operações mais comuns dentro do Tensorflow é a multiplicação matricial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 3  4]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicando tensores com a função do Tensorflow}\n",
    "print(tensor_1, '\\n')\n",
    "\n",
    "tf.matmul(tensor_1, tensor_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicando tensores com a operação nativa do Python\n",
    "tensor_1 @ tensor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[13 15]\n",
      " [ 1  3]\n",
      " [13  5]], shape=(3, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 3 18  9]\n",
      " [12  9  8]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Criando um segundo tensor\n",
    "tf.random.set_seed(10)\n",
    "tensor_2 = tf.random.uniform(shape = (3, 2), minval = 1, maxval = 20, dtype = 'int32', seed = 10)\n",
    "print(tensor_2, '\\n')\n",
    "\n",
    "'''\n",
    "Multiplicando tensor_1 @ tensor_2 resulta em erro, pois as dimensões internas das matrizes não são iguais.\n",
    "Para haver uma multiplicação de matrizes, o número de colunas da primeira matriz deve ser igual ao número\n",
    "de linhas da segunda.\n",
    "'''\n",
    " \n",
    "tensor_3 = tf.random.uniform(shape = (2, 3), minval = 1, maxval = 20, dtype = 'int32', seed = 10)\n",
    "print(tensor_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[219, 369, 237],\n",
       "       [ 39,  45,  33],\n",
       "       [ 99, 279, 157]])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2 @ tensor_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, temos as seguintes regras para multiplicação de matrizes:\n",
    "\n",
    "- Os tensores a serem multiplicados devem ter dimensões internas iguais, isto é, o número de colunas do primeiro deve ser igual ao número de linhas do segundo.\n",
    "- O tensor resultante tem o formato das dimensões externas dos tensores que foram multiplicados - neste caso temos uma matriz 3x3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape e Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tentamos multiplicar o tensor por ele mesmo, a menos que seja uma matriz quadrada, resultará num erro devido ao formato do tensor. Para manipular as dimensões de modo a coincidir as colunas do primeiro com as linhas do segundo, usamos a função `reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[13 15  1]\n",
      " [ 3 13  5]], shape=(2, 3), dtype=int32) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[214, 390,  88],\n",
       "       [ 22,  54,  16],\n",
       "       [184, 260,  38]])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.reshape(tensor_2, shape = [2, 3]),'\\n')\n",
    "\n",
    "tensor_2 @ tf.reshape(tensor_2, shape = [2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função reshape embaralha os valores de modo que eles fiquem no formato que você quer. Outro método usado para mudar o formato das matrizes é o `Transpose`. Nesta função, a diferença é que os eixos são transpostos, ao invés do formato ser construído a partir do embaralhamento dos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[13,  1, 13],\n",
       "        [15,  3,  5]])>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[13, 15,  1],\n",
       "        [ 3, 13,  5]])>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(tensor_2), tf.reshape(tensor_2, shape = [2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[165, 350],\n",
       "       [117, 346]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.transpose(tensor_2), tf.reshape(tensor_3, shape = [3, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[13, 15],\n",
       "        [ 1,  3],\n",
       "        [13,  5]])>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[ 3, 18,  9],\n",
       "        [12,  9,  8]])>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2, tensor_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 2 Normal: \n",
      "[[13 15]\n",
      " [ 1  3]\n",
      " [13  5]] \n",
      "\n",
      "Tensor 2 Reshape: \n",
      "[[13 15  1]\n",
      " [ 3 13  5]] \n",
      "\n",
      "Tensor 2 Transposto: \n",
      "[[13  1 13]\n",
      " [15  3  5]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Tensor 2 Normal:',\n",
    "      f'\\n{tensor_2}', \n",
    "      '\\n')\n",
    "\n",
    "print('Tensor 2 Reshape:',\n",
    "      f'\\n{tf.reshape(tensor_2, shape = [2, 3])}', \n",
    "      '\\n')\n",
    "\n",
    "print('Tensor 2 Transposto:',\n",
    "      f'\\n{tf.transpose(tensor_2)}', \n",
    "      '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mudando o tipo dos dados do tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os tipos dos dados em um tensor ocupam um espaço determinado de armazenamento e, dependendo do tipo específico dos dados, a precisão pode ser maior ou menor. Logicamente, dados com precisões maiores, i.e, mais casas decimais, tendem a ocupar maior espaço na memória além de requerer maior poder de processamento. \n",
    "\n",
    "Por isso, é importante conhecer os tipos de dados e como eles interagem com as unidades de processamento do Tensorflow. Por exemplo, o _float32_ ou _int32_ são tipos de dados que ocupam 32 bits de processamento na GPU. Para situações em que os dados não precisam de tamanha precisão, é importante modificá-los para tipos que ocupam menos espaço, de modo que o processamento passe a ser mais eficiente na hora do treinamento de longas listas de dados em formas de tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float32, tf.int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar um tensor com o tipo de dados float32\n",
    "B = tf.constant([1.7, 3.1])\n",
    "C = tf.constant([4, 1])\n",
    "B.dtype, C.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por padrão, o Tensorflow utiliza do _int32_ ou _float32_ para armazenamento dos dados.\n",
    "\n",
    "Para mudar o tipo, utilizamos o método `tf.cast()` especificando no argumento _dtype_ qual o tipo que queremos. Neste caso, estamos convertendo o _float_ de 32 para 16 bits de armazenamento, o que num contexto de milhões de dados, resultaria num ganho de performance grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 3.1], dtype=float16)>,\n",
       " tf.float32,\n",
       " tf.float16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mudar o tipo dos dados de float32 para float16 (redução de precisão)\n",
    "D = tf.cast(B, dtype = tf.float16) # Casts a tensor to a new type.\n",
    "D, B.dtype, D.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregação de tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prática de agregar tensores consiste em condensar múltiplos valores para um conjunto menor de valores significativos, que refletem o comportamento global dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor original: tf.Tensor([-3 -7], shape=(2,), dtype=int32)\n",
      "Valor absoluto: tf.Tensor([3 7], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Valores absolutos (módulo)\n",
    "E = tf.constant([-3, -7])\n",
    "print('Tensor original:', E)\n",
    "print('Valor absoluto:', tf.abs(E))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forma de agregar valores em tensores:\n",
    "\n",
    "- Valor máximo\n",
    "- Valor mínimo \n",
    "- Média do tensor\n",
    "- Soma do tensor\n",
    "\n",
    "Vamos criar um tensor aleatório e aplicar as funções agregadoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 5), dtype=int32, numpy=\n",
       "array([[[11, 28,  9, 42, 17],\n",
       "        [29, 32, 20,  2, 40],\n",
       "        [21,  9, 28,  4, 24],\n",
       "        [44, 12, 22, 29, 26]],\n",
       "\n",
       "       [[16, 27, 41, 15, 19],\n",
       "        [29,  3, 38,  8,  1],\n",
       "        [ 0, 24, 45, 38, 37],\n",
       "        [42, 29, 17, 24, 43]]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(20)\n",
    "agg_tensor = tf.random.uniform(shape = [2, 4, 5], minval = 0, maxval = 50, seed = 20, dtype = tf.int32)\n",
    "agg_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=45>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=23>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=945>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valor máximo\n",
    "'''\n",
    "Computes tf.math.maximum of elements across dimensions of a tensor.\n",
    "'''\n",
    "max_val = tf.reduce_max(agg_tensor)\n",
    "\n",
    "# Valor mínimo\n",
    "'''\n",
    "Computes the tf.math.minimum of elements across dimensions of a tensor.\n",
    "'''\n",
    "min_val = tf.reduce_min(agg_tensor)\n",
    "\n",
    "# Média\n",
    "'''\n",
    "Computes the mean of elements across dimensions of a tensor.\n",
    "'''\n",
    "mean_val = tf.reduce_mean(agg_tensor, )\n",
    "\n",
    "# Soma\n",
    "'''\n",
    "Computes the sum of elements across dimensions of a tensor.\n",
    "'''\n",
    "sum_val = tf.reduce_sum(agg_tensor)\n",
    "\n",
    "max_val, min_val, mean_val, sum_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 5), dtype=int32, numpy=\n",
       " array([[27, 55, 50, 57, 36],\n",
       "        [58, 35, 58, 10, 41],\n",
       "        [21, 33, 73, 42, 61],\n",
       "        [86, 41, 39, 53, 69]])>,\n",
       " <tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       " array([[105,  81,  79,  77, 107],\n",
       "        [ 87,  83, 141,  85, 100]])>,\n",
       " <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
       " array([[107, 123,  86, 133],\n",
       "        [118,  79, 144, 155]])>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variações no axis\n",
    "tf.reduce_sum(agg_tensor, axis = 0), tf.reduce_sum(agg_tensor, axis = 1), tf.reduce_sum(agg_tensor, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note o seguinte:\n",
    "- Soma no axis = 0 é a soma elemento por elemento de cada dimensão\n",
    "- Soma no axis = 1 é a soma dos elementos de cada coluna\n",
    "- Soma no axis = 2 é a soma dos elementos em cada linha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
