{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seção 2 - Deep Learning and Tensorflow Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definições"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deep Learning**: é uma sub-área de Machine Learning que envolve o aprendizado profundo de máquina, em que algoritmos buscam padrões em fontes de dados desestruturados, como textos, imagens, áudios. A modelagem acontece pelas redes neurais, que são estruturas que recebem, processam e constroem os modelos a partir dos dados, além de corrigir os erros e otimizar os parâmetros para aumentar a acurácia desses modelos. Assim, o Deep Learning atua como uma arquitetura de processamento e modelagem de dados não-estruturados, de forma automatizada a partir dos dados de input, resultando em previsões do objeto real em questão.\n",
    "\n",
    "- **Redes Neurais**: As redes neurais são estruturas de processamento de dados que formam a arquitetura do Deep Learning. Como disse logo acima, elas buscam imitar o processo da cognição humana ao conectar diversas camadas de neurônios artificiais.Esses neurônios atuam combinando os dados recebidos, atribuindo-lhes pesos e vieses e associando-os a funções específicas de custo e ativação. Dessa forma, esses elementos trabalham juntos para definir as etapas de processamento até o output, que deve reconhecer, classificar ou descrever objetos reais a partir dos dados.\n",
    "\n",
    "No Machine Learning, temos dados que são, na maioria das vezes, estruturados, e o procedimento de treinamento de um modelo com regras que encontramos ao manipular e processar os dados, além de haver um valor-alvo para basearmos a resposta do modelo em cada exemplo. No Deep Learning, temos apenas um input e um output esperado, e deixamos que as redes neurais processem os dados, encontrem alguma forma de estruturá-los e busquem por padrões que possam ajudar a chegar no resultado do output que esperamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um problema complexo, como ensinar um carro a dirigir sozinho, que possui um volume muito grande de dados, o Deep Learning pode ser a alternativa mais viável. Uma vez que estamos lidando com dados desestruturados e em grande volume, a estrutura de redes neurais traz uma capacidade de lidar de maneira mais eficiente com uma variedade de parâmetros e filtrá-los de acordo com sua relevância em cada camada.\n",
    "\n",
    "**O Deep Learning é indicado para as seguintes situações:**\n",
    "\n",
    "- Problemas com longas listas de regras\n",
    "- Ambientes que mudam constantemente, i.e, Adaptação a novos cenários\n",
    "- Descobrir insights em grandes quantidades de dados\n",
    "\n",
    "**Deep Learning não é indicado nas seguintes situações:**\n",
    "\n",
    "- Quando necessitamos interpretabilidade: os padrões de DL normalme}nte não são interpretáveis por humanos\n",
    "- Quando a abordagem tradicional é melhor, isto é, com um sistema de regras simples\n",
    "- Quando erros são inaceitáveis, pois outputs no DL podem ser imprevisíveis \n",
    "- Quando não há muitos dados disponíveis, pois modelos de DL necessitam de grandes quantidade de dados para manter uma boa performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow é uma biblioteca de Machine Learning end-to-end. Nela, é possível escrever códigos de DL em Python e rodá-los utilizando GPU (Graphics Processing Units) ou TPU (Tensor Processing Units). O Tensorflow permite o pré-processamento dos dados, modelagem e deploy de aplicações, além de oferecer um hub de modelos já construídos de DL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do Tensorflow: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Versão do Tensorflow: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.constant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar tensores com tf.constant()\n",
    "scalar = tf.constant(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um tensor constante de ordem zero, ou seja, um escalar. O escalar é simplesmente a representação de um número. Se checarmos o número de dimensões desse tensor escalar, resultará em:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {scalar.ndim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 2])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = tf.constant([7, 2])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que, para criar um vetor, passamos uma lista de números para a função `tf.constant()`. Vamos checar as dimensões do vetor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {vector.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de se esperar, o vetor já é um tensor de grau 1, contendo portanto uma dimensão. Se aumentarmos a dimensão, teremos uma matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 2],\n",
       "       [3, 6]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tf.constant([[5, 2],\n",
    "                     [3, 6]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {matrix.ndim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float16, numpy=\n",
       "array([[ 3.,  5.,  1.],\n",
       "       [ 5., 12., 43.],\n",
       "       [ 2.,  5.,  8.]], dtype=float16)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Especificando o tipo dos dados no tensor\n",
    "matrix_2 = tf.constant([[3., 5., 1.],\n",
    "                        [5., 12., 43.],\n",
    "                        [2., 5., 8.]], dtype = tf.float16)\n",
    "matrix_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipular os tipos dos dados é útil, pois pode economizar espaço de armazenamento das variáveis nas unidades de processamento, tornando os processos mais rápidos. Para número que não carregam tanta precisão, podemos utilizar um tipo de dados que ocupa menos espaço.\n",
    "\n",
    "Note que essa matriz possui um formato diferente da primeira, contudo o número de dimensões continua o mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {matrix_2.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, para criar um tensor, precisamos aumentar a dimensão mais uma vez para ter um tensor de grau 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[1, 2, 4],\n",
       "        [2, 5, 7]],\n",
       "\n",
       "       [[4, 1, 6],\n",
       "        [6, 8, 8]],\n",
       "\n",
       "       [[4, 6, 1],\n",
       "        [6, 2, 1]]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant([[[1, 2, 4],\n",
    "                       [2, 5, 7]], \n",
    "                       [[4, 1, 6],\n",
    "                       [6, 8, 8]],\n",
    "                       [[4, 6, 1],\n",
    "                        [6, 2, 1]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preste atenção ao _shape_, temos 3 matrizes, de 2 linhas e 3 colunas cada. Vamos checar as dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de dimensões: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de dimensões: {tensor.ndim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criado portanto um tensor de grau 3. Assim, criamos diferentes tipos de tensores que variam em seu grau, ou dimensões:\n",
    "\n",
    "- Escalar: tensor de grau zero;\n",
    "- Vetor: tensor de grau 1 (e.g, Força);\n",
    "- Matrix: tensor de grau 2 (e.g, Matriz de condutividade);\n",
    "- Tensor: um arranjo numérico n-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.Variable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentemente do `tf.constant()`, o `tf.Variable()` criar tensores cujos elementos podem mudar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 1])>,\n",
       " <tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([5, 1])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando tensores constantes e variáveis\n",
    "unchangeable_tensor = tf.constant([5, 1])\n",
    "changeable_tensor = tf.Variable([5, 1])\n",
    "\n",
    "unchangeable_tensor, changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([6, 1])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alterando elementos do tensor variável\n",
    "changeable_tensor[0].assign(6)\n",
    "\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que foi alterado o primeiro elemento do tensor variável. Se tentarmos fazer o mesmo com o tensor constante, obviamente teríamos um erro, pois os elementos não podem mudar.\n",
    "\n",
    "Raramente será preciso decidir entre usar o tensor constante ou o variável. Durante as aplicações, o próprio TensorFlow toma essa decisão por nós."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensores randômicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensores randômicos são tensores de tamanho arbitrário que contém números gerados aleatoriamente. As redes neurais utilizam tensores randômics para inicializar os pesos dos parâmetros ao receber dados de input, sendo o primeiro passo para compreender os dados. Por exemplo, o processo de aprendizado da rede neural envolve tomar um arranjo n-dimensional de número e refiná-lo até que ele represente algum padrão (uma forma comprimida de representar os dados originais)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.7565803 , -0.06854702],\n",
       "        [ 0.07595026, -1.2573844 ],\n",
       "        [-0.23193763, -1.8107855 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando dois tensores aleatórios (porém iguais)\n",
    "random_1 = tf.random.Generator.from_seed(42)\n",
    "random_1 = random_1.normal(shape = (3, 2))\n",
    "\n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape = (3, 2))\n",
    "\n",
    "random_1, random_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       "array([[ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_1 == random_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que apesar de os números parecerem randômicos, eles não são realmente. Por termos definido uma _seed_ para o gerador de números aleatórios, e depois termos pedido para gerar os números aleatórios de acordo com uma distribuição qualquer (neste caso, a normal), a _seed_ garante a reproducibilidade dos dados. É como se pedíssemos números aleatórios, mas com um tempero específico, que é a _seed_. Assim, ambos os tensores contém a mesma _seed_ de geração, de modo que ao aplicar a mesma distribuição, eles serão iguais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embaralhando a ordem dos elementos no tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual a necessidade de embaralhar elementos em um tensor?\n",
    "\n",
    "A ordem dos dados pode afetar a maneira como a rede neural aprende, de modo que ela começa a organizar seus pesos de acordo com o padrão que encontrou devido simplesmente ao ordenamento dos dados, não porque identificou características nos atributos que realmente diferenciam os objetos na realidade.\n",
    "\n",
    "Vamos supor que temos um conjunto de dados que contém 10000 imagens de gatos seguidas por 5000 imagens de cachorros. Por causa das primeiras 10 mil imagens serem apenas de gatos, o algoritmo pode perceber a ordem e classificar de acordo com isso, ao invés de padrões subjacentes nos dados. Isso pode levar ao overfitting do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[4, 3],\n",
       "       [1, 4],\n",
       "       [5, 7]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_shuffled = tf.constant([[4, 3],\n",
    "                            [1, 4],\n",
    "                            [5, 7]])\n",
    "not_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[4, 3],\n",
       "       [5, 7],\n",
       "       [1, 4]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Emabaralhando o tensor\n",
    "shuffled = tf.random.shuffle(not_shuffled)\n",
    "shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[4, 3],\n",
       "       [5, 7],\n",
       "       [1, 4]])>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embaralhando com uma seed para geração\n",
    "tf.random.set_seed(10) # seed global\n",
    "seed_shuffle = tf.random.shuffle(not_shuffled, seed = 10) # seed operacional\n",
    "seed_shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que no primeiro caso, em que apenas embaralhamos os elementos dos tensor, a cada atualização na célula temos uma nova ordem de elementos no tensor. No segundo caso, em que definimos uma _seed_ global e uma operacional, e as duas são iguais, os elementos são embaralhados, mas a _seed_ garante a reproducibilidade a cada atualização da célula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando tensores de arrays NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
